"use strict";
/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/. */
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.BlockHeaderSerde = exports.BlockHeader = exports.transactionMerkleRoot = exports.transactionCommitment = exports.NULL_NODE = exports.TRANSACTION_ROOT_PERSONALIZATION = exports.isBlockHeavier = exports.isBlockLater = exports.hashBlockHeader = void 0;
const blake_hash_1 = require("@napi-rs/blake-hash");
const assert_1 = require("../assert");
const serde_1 = require("../serde");
const PartialHeaderSerde_1 = __importDefault(require("../serde/PartialHeaderSerde"));
const bigint_1 = require("../utils/bigint");
const target_1 = require("./target");
function hashBlockHeader(serializedHeader) {
    return blake_hash_1.blake3(serializedHeader);
}
exports.hashBlockHeader = hashBlockHeader;
function isBlockLater(a, b) {
    if (a.sequence !== b.sequence) {
        return a.sequence > b.sequence;
    }
    return a.hash.compare(b.hash) < 0;
}
exports.isBlockLater = isBlockLater;
function isBlockHeavier(a, b) {
    if (a.work !== b.work) {
        return a.work > b.work;
    }
    if (a.sequence !== b.sequence) {
        return a.sequence > b.sequence;
    }
    if (a.target.toDifficulty() !== b.target.toDifficulty()) {
        return a.target.toDifficulty() > b.target.toDifficulty();
    }
    return a.hash.compare(b.hash) < 0;
}
exports.isBlockHeavier = isBlockHeavier;
exports.TRANSACTION_ROOT_PERSONALIZATION = Buffer.from('IRON_FISH_TRANSACTION_ROOT');
exports.NULL_NODE = blake_hash_1.blake3(Buffer.from([0]));
/**
 * Calculate a commitment to a list of transactions in a block by adding
 * the transaction hashes (including witness data) to a merkle tree and returning the merkle root
 * @param transactions transaction in the block
 * @returns 32-byte commitment to the list of transactions
 */
function transactionCommitment(transactions) {
    const transactionHashes = transactions.map((t) => t.hash());
    return transactionMerkleRoot(transactionHashes);
}
exports.transactionCommitment = transactionCommitment;
// Implementation similar to ZCash AuthDataMerkleRoot
// https://github.com/zcash/zcash/blob/14cce06163019ab0a16adb944d25f7db68c012c6/src/primitives/block.cpp#L54
function transactionMerkleRoot(hashes) {
    if (hashes.length === 0) {
        return blake_hash_1.blake3(exports.TRANSACTION_ROOT_PERSONALIZATION);
    }
    // Get the number of nodes needed for a perfectly balanced tree
    const perfectSize = hashes.length === 1 ? 2 : 2 ** Math.ceil(Math.log2(hashes.length));
    assert_1.Assert.isTrue(perfectSize >= hashes.length);
    assert_1.Assert.isGreaterThan(perfectSize, 1);
    assert_1.Assert.isEqual(perfectSize & (perfectSize - 1), 0);
    let currentLevelHashes = hashes;
    while (currentLevelHashes.length < perfectSize) {
        currentLevelHashes.push(exports.NULL_NODE);
    }
    assert_1.Assert.isEqual(perfectSize, currentLevelHashes.length);
    let currentLevel = 0;
    while (currentLevelHashes.length > 1) {
        const nextLevelHashes = [];
        for (let i = 0; i < currentLevelHashes.length; i += 2) {
            // Add personalization so these hashes cannot be replayed to/from different contexts
            // Also add in the level of the currentLevel to be resilient to second pre-image attacks
            const combination = blake_hash_1.blake3(Buffer.concat([
                exports.TRANSACTION_ROOT_PERSONALIZATION,
                Buffer.from([currentLevel]),
                currentLevelHashes[i],
                currentLevelHashes[i + 1],
            ]));
            nextLevelHashes.push(combination);
        }
        currentLevelHashes = nextLevelHashes;
        currentLevel++;
    }
    return currentLevelHashes[0];
}
exports.transactionMerkleRoot = transactionMerkleRoot;
class BlockHeader {
    constructor(sequence, previousBlockHash, noteCommitment, transactionCommitment, target, randomness = BigInt(0), timestamp = undefined, graffiti, noteSize, work = BigInt(0), hash) {
        this.sequence = sequence;
        this.previousBlockHash = previousBlockHash;
        this.noteCommitment = noteCommitment;
        this.transactionCommitment = transactionCommitment;
        this.target = target;
        this.randomness = randomness;
        this.timestamp = timestamp || new Date();
        this.graffiti = graffiti;
        this.noteSize = noteSize ?? null;
        this.work = work;
        this.hash = hash || this.recomputeHash();
    }
    /**
     * Construct a partial block header without the randomness and convert
     * it to buffer.
     *
     * This is used for calculating the hash in miners and for verifying it.
     */
    serializePartial() {
        return PartialHeaderSerde_1.default.serialize({
            sequence: this.sequence,
            previousBlockHash: this.previousBlockHash,
            noteCommitment: this.noteCommitment,
            transactionCommitment: this.transactionCommitment,
            target: this.target,
            timestamp: this.timestamp,
            graffiti: this.graffiti,
        });
    }
    /**
     * Hash all the values in the block header to get a commitment to the entire
     * header and the global trees it models.
     */
    recomputeHash() {
        const partialHeader = this.serializePartial();
        const headerBytes = Buffer.alloc(partialHeader.byteLength + 8);
        headerBytes.set(bigint_1.BigIntUtils.writeBigU64BE(this.randomness));
        headerBytes.set(partialHeader, 8);
        const hash = hashBlockHeader(headerBytes);
        this.hash = hash;
        return hash;
    }
    /**
     * Check whether the hash of this block is less than the target stored
     * within the block header. This is the primary proof of work function.
     *
     * Hashes cannot be predicted, and the only way to find one that is lower
     * than the target that is inside it is to tweak the randomness number
     * repeatedly.
     */
    verifyTarget() {
        return target_1.Target.meets(bigint_1.BigIntUtils.fromBytesBE(this.recomputeHash()), this.target);
    }
    equals(other) {
        return (this.noteSize === other.noteSize &&
            this.work === other.work &&
            this.recomputeHash().equals(other.recomputeHash()));
    }
}
exports.BlockHeader = BlockHeader;
class BlockHeaderSerde {
    static serialize(header) {
        const serialized = {
            sequence: header.sequence,
            previousBlockHash: serde_1.BlockHashSerdeInstance.serialize(header.previousBlockHash),
            noteCommitment: header.noteCommitment,
            transactionCommitment: header.transactionCommitment,
            target: header.target.targetValue.toString(),
            randomness: header.randomness.toString(),
            timestamp: header.timestamp.getTime(),
            graffiti: serde_1.GraffitiSerdeInstance.serialize(header.graffiti),
            noteSize: header.noteSize,
            work: header.work.toString(),
        };
        return serialized;
    }
    static deserialize(data) {
        return new BlockHeader(Number(data.sequence), Buffer.from(serde_1.BlockHashSerdeInstance.deserialize(data.previousBlockHash)), data.noteCommitment, data.transactionCommitment, new target_1.Target(data.target), BigInt(data.randomness), new Date(data.timestamp), Buffer.from(serde_1.GraffitiSerdeInstance.deserialize(data.graffiti)), data.noteSize, data.work ? BigInt(data.work) : BigInt(0));
    }
}
exports.BlockHeaderSerde = BlockHeaderSerde;
//# sourceMappingURL=blockheader.js.map